{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ea284f1-569a-4e68-9dac-e3f8e5296656",
   "metadata": {},
   "source": [
    "# Explanation of K-Fold Cross-Validation\n",
    "K-Fold Cross-Validation is a resampling procedure used to evaluate the performance of machine learning models. It divides the dataset into K equally sized folds (subsets). The model is trained and evaluated K times, each time using a different fold as the validation set and the remaining K-1 folds as the training set. This process ensures that every data point is used for both training and validation exactly once.\n",
    "\n",
    "## Benefits and Use Cases of K-Fold Cross-Validation\n",
    "## Benefits\n",
    "- 1**More Reliable Estimates**: Provides a more reliable estimate of model performance compared to a single train-test split, as it reduces the variability associated with a particular train-test split.\n",
    "- \n",
    "**Better Utilization of Data**: Uses all the data points for both training and validation, maximizing the use of available data.\n",
    "-  \n",
    "**Bias-Variance Trade-off**: Helps in understanding the bias-variance trade-off by providing insights into how well the model generalizes to unseen data.\n",
    "\n",
    "## Use Cases\n",
    "**Model Selection**: Helps in selecting the best model among different algorithms by comparing their cross-validated performance.\n",
    "\n",
    "**Hyperparameter Tuning**: Used in conjunction with grid search or random search to tune hyperparameters, ensuring that the model is not overfitted to a                                specific train-test split.\n",
    "\n",
    "**Performance Evaluation**: Provides a robust estimate of model performance, which is crucial when dealing with small datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57b9a51c-caf7-4602-b6c3-d41155059f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2afc4601-cd8e-490f-a405-0cb30deeb934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53ce211b-af44-49e8-b0bb-2ad57a0897e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the K-Fold cross-validator\n",
    "kf=KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "288aae40-e4cf-493d-916f-b849b8e0bcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = DecisionTreeClassifier()\n",
    "score=cross_val_score(model,X,y,cv=kf,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e566e1a7-8aef-43a4-b26a-0ba78d9d9d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [1.         0.96666667 0.93333333 0.93333333 0.93333333]\n",
      "Mean Accuracy: 0.9533333333333335\n",
      "Standard Deviation: 0.02666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Print the cross-validation scores\n",
    "print(\"Cross-Validation Scores:\", score)\n",
    "print(\"Mean Accuracy:\", score.mean())\n",
    "print(\"Standard Deviation:\", score\n",
    "      .std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91854a47-89a0-4feb-9688-4c05defeb619",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "K-Fold Cross-Validation is a powerful technique for evaluating the performance of machine learning models. By dividing the dataset into K folds and training the model K times on different train-test splits, it provides a more reliable estimate of model performance and helps in better utilization of data. This method is particularly useful for model selection, hyperparameter tuning, and performance evaluation.\n",
    "\n",
    "\n",
    "Implementing K-Fold and Stratified K-Fold Cross-Validation in Python using libraries like Scikit-learn allows for robust and efficient model evaluation, ultimately leading to better-performing models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0264c6ff-72ee-4dc3-a4d0-86ccaf56374b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad644fd8-7996-4dc6-9f02-7933d90884e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
